{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Gap (prelaunch) 0.9 - July 2018\n",
    "## NLP and CV Data Engineering Framework\n",
    "\n",
    "<b>[Github] (https://github.com/andrewferlitsch/gap)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Preparation for NLP with Gap (Session 2)\n",
    "\n",
    "Let's dig deeper into the basics. We will be using the <b style='color: saddlebrown'>SYNTAX</b> component in my Gap module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: saddlebrown'>Words</span> Object\n",
    "\n",
    "Let's directly use the <b style='color: saddlebrown'>Words</b> object to control how the text is NLP preprocessed.I will cover the following:\n",
    "\n",
    "    - Syntax Preprocessing\n",
    "    - Text Reduction (Stopwords)\n",
    "    - Parts of Speech Tagging\n",
    "    - De-Identification\n",
    "    - Measurement Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\'\\Desktop\\epipog-nlp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\'\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\'\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# import the Words class\n",
    "from document import Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax Preprocessing\n",
    "\n",
    "The <b style='color: saddlebrown'>SYNTAX</b> module supports various keyword parameters to configure how the text is NLP preprocessed. We will cover just a few in this code-along. Let's start with processing text for gender recognition. When the text is preprocessed, an ordered sequential list of Word objects are generated; each consisting a set of key/value pairs.\n",
    "\n",
    "In bare mode, all the text and punctuation is preserved, and no tagging, parts of speech (POS), stemming, lemmatization, name entity recognition (NER) or stopword removal is perform.\n",
    "\n",
    "#### Bare\n",
    "\n",
    "Let's look at the preprocessing of a simple sentence in bare mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'The', 'tag': 0}, {'word': 'quick', 'tag': 0}, {'word': 'brown', 'tag': 0}, {'word': 'fox', 'tag': 0}, {'word': 'jumped', 'tag': 0}, {'word': 'over', 'tag': 0}, {'word': 'the', 'tag': 0}, {'word': 'lazy', 'tag': 0}, {'word': 'dog', 'tag': 0}, {'word': '.', 'tag': 23}]\n"
     ]
    }
   ],
   "source": [
    "# Process this well-known typing phrase which contains all 26 letters of the alphabet\n",
    "w = Words('The quick brown fox jumped over the lazy dog.', bare=True)\n",
    "print(w.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the words property displays a list, where each entry is an object consisting of a word and tag key value pair. I know you don't know what the integer values of the tags mean (see Vocabulary.py). In bare mode, all words are tagged as UNTAGGED (0) and punctuation as PUNCT (23).\n",
    "\n",
    "Note how in bare mode, all words are kept, their capitalization, order and punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords and Stemming\n",
    "\n",
    "Let's do some text reduction. In NLP, a lot of things add very little to the understanding of the text, such as common words like 'the', 'and', 'a', and punctuation. Removing these common words is called stopword removal. There are several lists for doing this, the most common being the Porter list.\n",
    "\n",
    "Additionallly, we can make it easier to match words if we lowercase all the words and remove word endings, such as plural and 'ing'; which is called stemming. Let's give it a try with the same sentence.\n",
    "\n",
    "Note how words like 'the', and 'over' have been removed, the punctuation has been removed, words have been lowercased and 'jumped' has been stemmed to its root word 'jump'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'quick', 'tag': 0}, {'word': 'brown', 'tag': 0}, {'word': 'fox', 'tag': 0}, {'word': 'jump', 'tag': 0}, {'word': 'lazi', 'tag': 0}, {'word': 'dog', 'tag': 0}]\n"
     ]
    }
   ],
   "source": [
    "w = Words('The quick brown fox jumped over the lazy dog.', stem='porter')\n",
    "print(w.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 15, 'word': 'grandfather'},\n",
       " {'tag': 0, 'word': 'son'},\n",
       " {'tag': 15, 'word': 'dad'},\n",
       " {'tag': 16, 'word': 'sister'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w = Words(\"grandfather, son, dad, sister\", gender=True)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER (Name Entity Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a string with a name and social security number.\n",
    "w = Words(\" word1 word2 Jim Jones, SSN: 123-12-1234 word3\", stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 0, 'word': 'word1'},\n",
       " {'tag': 0, 'word': 'word2'},\n",
       " {'tag': 11, 'word': 'jim'},\n",
       " {'tag': 11, 'word': 'jones'},\n",
       " {'tag': 9, 'word': '123121234'},\n",
       " {'tag': 0, 'word': 'word3'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print the word list. Note that jim and jones are tagged 11 (Proper Name) and 123121234 is tagged 9 (SSN)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De-Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 0, 'word': 'word1'},\n",
       " {'tag': 0, 'word': 'word2'},\n",
       " {'tag': 0, 'word': 'word3'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remove any names and SSN from our text\n",
    "w = Words(\"  word1 word2 Jim Jones, SSN: 123-12-1234 word3\", name=False, ssn=False)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THAT'S ALL FOR SESSION 1\n",
    "\n",
    "Look forward to seeing everyone again on session 2 where we will do some serious deep diving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
